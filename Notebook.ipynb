{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.layers import *\nfrom keras.models import * \nfrom keras.losses import *\nfrom keras.preprocessing import image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Creating a model for the given dataset of 62 classes (including numbers and letters)","metadata":{}},{"cell_type":"code","source":"inp=Input(shape=(400,400,1))\nX=Conv2D(32,(3,3), activation='relu')(inp)\nX=MaxPooling2D(2,2)(X)\n\nX=Conv2D(32,(3,3), activation='relu')(X)\nX=MaxPooling2D(pool_size=(2,2))(X)\n\nX=Conv2D(64,(3,3), activation='relu')(X)\nX=MaxPooling2D(pool_size=(2,2))(X)\n\n\nX=Conv2D(128,(3,3), activation='relu')(X)\nX=MaxPooling2D(pool_size=(2,2))(X)\n\n\nX=Flatten()(X)\nX=Dense(128, activation='relu')(X)\nX=Dense(62, activation='softmax')(X)\nmodel=Model(inputs=inp,outputs=X)\n\nmodel.compile(loss=sparse_categorical_crossentropy,optimizer='rmsprop',metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 400, 400, 1)]     0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 398, 398, 32)      320       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 199, 199, 32)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 197, 197, 32)      9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 98, 98, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 96, 96, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 48, 48, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 46, 46, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 23, 23, 128)       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 67712)             0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               8667264   \n_________________________________________________________________\ndense_1 (Dense)              (None, 62)                7998      \n=================================================================\nTotal params: 8,777,182\nTrainable params: 8,777,182\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training the model on the given data (62 classes)","metadata":{}},{"cell_type":"code","source":"train_datagen = image.ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, validation_split=0.2)\ntrain_data_path='../input/mnist-numbers-train-and-valid/MNIST Numbers only NEW/Train'\ntrain_generator = train_datagen.flow_from_directory(train_data_path ,target_size=(400, 400),batch_size=32,class_mode='binary',color_mode=\"grayscale\")\nvalid_datagen = image.ImageDataGenerator(rescale=1./255)\nval_data='../input/mnist-numbers-train-and-valid/MNIST Numbers only NEW/Valid'\nvalidation_generator = valid_datagen.flow_from_directory(val_data,target_size=(400, 400),batch_size=32, class_mode='binary',color_mode=\"grayscale\")\n\nmodel.fit(train_generator,steps_per_epoch=28,epochs=30,validation_data=validation_generator,validation_steps=8)","metadata":{"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 2170 images belonging to 62 classes.\nFound 310 images belonging to 62 classes.\nEpoch 1/30\n28/28 [==============================] - 32s 1s/step - loss: 4.4452 - accuracy: 0.0233 - val_loss: 4.0485 - val_accuracy: 0.0508\nEpoch 2/30\n28/28 [==============================] - 27s 973ms/step - loss: 3.9488 - accuracy: 0.0753 - val_loss: 3.6676 - val_accuracy: 0.0898\nEpoch 3/30\n28/28 [==============================] - 27s 953ms/step - loss: 3.2256 - accuracy: 0.2079 - val_loss: 3.5071 - val_accuracy: 0.1406\nEpoch 4/30\n28/28 [==============================] - 26s 940ms/step - loss: 2.5026 - accuracy: 0.3706 - val_loss: 3.2594 - val_accuracy: 0.2461\nEpoch 5/30\n28/28 [==============================] - 26s 925ms/step - loss: 2.1927 - accuracy: 0.4485 - val_loss: 2.7994 - val_accuracy: 0.3281\nEpoch 6/30\n28/28 [==============================] - 26s 937ms/step - loss: 1.7240 - accuracy: 0.5771 - val_loss: 3.1525 - val_accuracy: 0.3125\nEpoch 7/30\n28/28 [==============================] - 26s 928ms/step - loss: 1.5029 - accuracy: 0.6204 - val_loss: 2.9376 - val_accuracy: 0.3867\nEpoch 8/30\n28/28 [==============================] - 26s 934ms/step - loss: 1.2601 - accuracy: 0.6777 - val_loss: 2.8463 - val_accuracy: 0.4570\nEpoch 9/30\n28/28 [==============================] - 26s 921ms/step - loss: 1.1779 - accuracy: 0.6749 - val_loss: 3.0455 - val_accuracy: 0.4180\nEpoch 10/30\n28/28 [==============================] - 26s 915ms/step - loss: 0.9302 - accuracy: 0.7523 - val_loss: 3.1789 - val_accuracy: 0.3984\nEpoch 11/30\n28/28 [==============================] - 26s 931ms/step - loss: 0.8367 - accuracy: 0.7847 - val_loss: 3.1521 - val_accuracy: 0.4102\nEpoch 12/30\n28/28 [==============================] - 26s 921ms/step - loss: 0.7193 - accuracy: 0.8029 - val_loss: 3.3716 - val_accuracy: 0.4375\nEpoch 13/30\n28/28 [==============================] - 26s 930ms/step - loss: 0.6602 - accuracy: 0.8115 - val_loss: 3.1735 - val_accuracy: 0.4570\nEpoch 14/30\n28/28 [==============================] - 26s 921ms/step - loss: 0.5447 - accuracy: 0.8624 - val_loss: 3.6790 - val_accuracy: 0.4727\nEpoch 15/30\n28/28 [==============================] - 26s 929ms/step - loss: 0.4584 - accuracy: 0.8748 - val_loss: 3.3453 - val_accuracy: 0.4609\nEpoch 16/30\n28/28 [==============================] - 26s 923ms/step - loss: 0.4252 - accuracy: 0.8828 - val_loss: 3.6035 - val_accuracy: 0.4688\nEpoch 17/30\n28/28 [==============================] - 26s 912ms/step - loss: 0.4034 - accuracy: 0.8951 - val_loss: 3.3405 - val_accuracy: 0.4688\nEpoch 18/30\n28/28 [==============================] - 26s 928ms/step - loss: 0.3377 - accuracy: 0.8923 - val_loss: 4.3103 - val_accuracy: 0.4219\nEpoch 19/30\n28/28 [==============================] - 26s 928ms/step - loss: 0.3749 - accuracy: 0.9023 - val_loss: 3.7518 - val_accuracy: 0.4648\nEpoch 20/30\n28/28 [==============================] - 26s 932ms/step - loss: 0.3301 - accuracy: 0.9113 - val_loss: 3.3681 - val_accuracy: 0.4961\nEpoch 21/30\n28/28 [==============================] - 25s 915ms/step - loss: 0.2535 - accuracy: 0.9266 - val_loss: 4.2823 - val_accuracy: 0.4609\nEpoch 22/30\n28/28 [==============================] - 25s 908ms/step - loss: 0.2441 - accuracy: 0.9320 - val_loss: 4.2012 - val_accuracy: 0.4297\nEpoch 23/30\n28/28 [==============================] - 26s 929ms/step - loss: 0.2506 - accuracy: 0.9464 - val_loss: 4.0090 - val_accuracy: 0.4609\nEpoch 24/30\n28/28 [==============================] - 26s 924ms/step - loss: 0.2256 - accuracy: 0.9382 - val_loss: 3.7875 - val_accuracy: 0.5078\nEpoch 25/30\n28/28 [==============================] - 26s 928ms/step - loss: 0.1771 - accuracy: 0.9577 - val_loss: 3.9858 - val_accuracy: 0.4961\nEpoch 26/30\n28/28 [==============================] - 26s 919ms/step - loss: 0.1992 - accuracy: 0.9412 - val_loss: 3.3362 - val_accuracy: 0.5234\nEpoch 27/30\n28/28 [==============================] - 26s 919ms/step - loss: 0.1392 - accuracy: 0.9602 - val_loss: 4.1095 - val_accuracy: 0.5469\nEpoch 28/30\n28/28 [==============================] - 26s 937ms/step - loss: 0.1760 - accuracy: 0.9378 - val_loss: 4.3325 - val_accuracy: 0.4766\nEpoch 29/30\n28/28 [==============================] - 26s 939ms/step - loss: 0.1059 - accuracy: 0.9673 - val_loss: 3.9341 - val_accuracy: 0.5156\nEpoch 30/30\n28/28 [==============================] - 26s 927ms/step - loss: 0.1567 - accuracy: 0.9451 - val_loss: 3.7016 - val_accuracy: 0.5195\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f7c38190c50>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Loading the model and training on MNIST numbers ","metadata":{}},{"cell_type":"code","source":"model.save(\"model.h5\") \nfrom keras.models import load_model\n# load model\nmodels = load_model('model.h5')\nmodels.summary()\n\n","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 400, 400, 1)]     0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 398, 398, 32)      320       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 199, 199, 32)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 197, 197, 32)      9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 98, 98, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 96, 96, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 48, 48, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 46, 46, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 23, 23, 128)       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 67712)             0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               8667264   \n_________________________________________________________________\ndense_1 (Dense)              (None, 62)                7998      \n=================================================================\nTotal params: 8,777,182\nTrainable params: 8,777,182\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Removing the output layer of the previous model\n- Here we remove the 62 output class layers of previous model","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.engine import InputLayer\nmodel2 = Model(models.input, models.layers[-2].output)\nmodel2.summary()\n","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"model_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 400, 400, 1)]     0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 398, 398, 32)      320       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 199, 199, 32)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 197, 197, 32)      9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 98, 98, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 96, 96, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 48, 48, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 46, 46, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 23, 23, 128)       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 67712)             0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               8667264   \n=================================================================\nTotal params: 8,769,184\nTrainable params: 8,769,184\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Adding a 10 class output layer for training the model on numbers only","metadata":{}},{"cell_type":"code","source":"X=Dense(10,activation='softmax')(model2.output)\nmodel2.summary()","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"model_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 400, 400, 1)]     0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 398, 398, 32)      320       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 199, 199, 32)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 197, 197, 32)      9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 98, 98, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 96, 96, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 48, 48, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 46, 46, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 23, 23, 128)       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 67712)             0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               8667264   \n=================================================================\nTotal params: 8,769,184\nTrainable params: 8,769,184\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model3=Model(model2.input,X)\nmodel3.summary()\n","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Model: \"model_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 400, 400, 1)]     0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 398, 398, 32)      320       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 199, 199, 32)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 197, 197, 32)      9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 98, 98, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 96, 96, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 48, 48, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 46, 46, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 23, 23, 128)       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 67712)             0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               8667264   \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 8,770,474\nTrainable params: 8,770,474\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tranfer learning training\ntrain_datagen = image.ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, validation_split=0.2)\ntrain_data_path='../input/mnist-numbers-only-train-valid-new/MNIST Numbers only NEW/Train'\ntrain_generator = train_datagen.flow_from_directory(train_data_path ,target_size=(400, 400),batch_size=32,class_mode='binary',color_mode=\"grayscale\")\nvalid_datagen = image.ImageDataGenerator(rescale=1./255)\nval_data='../input/mnist-numbers-only-train-valid-new/MNIST Numbers only NEW/Valid'\nvalidation_generator = valid_datagen.flow_from_directory(val_data,target_size=(400, 400),batch_size=32, class_mode='binary',color_mode=\"grayscale\")\nmodel3.compile(loss=sparse_categorical_crossentropy,optimizer='rmsprop',metrics=['accuracy'])\nmodel3.fit(train_generator,steps_per_epoch=5,epochs=10,validation_data=validation_generator,validation_steps=2)","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Found 350 images belonging to 10 classes.\nFound 50 images belonging to 10 classes.\nEpoch 1/10\n5/5 [==============================] - 7s 1s/step - loss: 5.5989 - accuracy: 0.1551 - val_loss: 2.0492 - val_accuracy: 0.2800\nEpoch 2/10\n5/5 [==============================] - 5s 1s/step - loss: 1.4557 - accuracy: 0.5484 - val_loss: 1.7261 - val_accuracy: 0.5000\nEpoch 3/10\n5/5 [==============================] - 5s 1s/step - loss: 1.2200 - accuracy: 0.6342 - val_loss: 1.4587 - val_accuracy: 0.5800\nEpoch 4/10\n5/5 [==============================] - 5s 1s/step - loss: 0.7485 - accuracy: 0.7793 - val_loss: 1.5591 - val_accuracy: 0.5800\nEpoch 5/10\n5/5 [==============================] - 5s 1s/step - loss: 0.5069 - accuracy: 0.8141 - val_loss: 1.3544 - val_accuracy: 0.5800\nEpoch 6/10\n5/5 [==============================] - 5s 1s/step - loss: 0.3634 - accuracy: 0.9120 - val_loss: 1.3544 - val_accuracy: 0.6000\nEpoch 7/10\n5/5 [==============================] - 6s 1s/step - loss: 0.1300 - accuracy: 0.9733 - val_loss: 1.2454 - val_accuracy: 0.6800\nEpoch 8/10\n5/5 [==============================] - 5s 1s/step - loss: 0.1277 - accuracy: 0.9694 - val_loss: 1.4700 - val_accuracy: 0.6600\nEpoch 9/10\n5/5 [==============================] - 5s 1s/step - loss: 0.2321 - accuracy: 0.9435 - val_loss: 1.5204 - val_accuracy: 0.6600\nEpoch 10/10\n5/5 [==============================] - 5s 1s/step - loss: 0.0413 - accuracy: 0.9894 - val_loss: 1.6664 - val_accuracy: 0.6800\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f7c38183590>"},"metadata":{}}]},{"cell_type":"code","source":"def inputchange(model,h,w,ch):\n    model._layers[0]._batch_input_shape = (None,h,w,ch)\n    new_model = keras.models.model_from_json(model.to_json())\n    return new_model\n\nnm=inputchange(model3,48,48,1)\nnm.summary()","metadata":{"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Model: \"model_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 48, 48, 1)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 46, 46, 32)        320       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 23, 23, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 21, 21, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 10, 10, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 8, 8, 64)          18496     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 2, 2, 128)         73856     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 128)               0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               16512     \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 119,722\nTrainable params: 119,722\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training on standard MNIST data","metadata":{}},{"cell_type":"code","source":"train_datagen = image.ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, validation_split=0.2)\ntrain_data_path='../input/mnist-standard-data/MNIST Standard set/training'\ntrain_generator = train_datagen.flow_from_directory(train_data_path ,target_size=(48, 48),batch_size=32,class_mode='binary',color_mode=\"grayscale\")\nvalid_datagen = image.ImageDataGenerator(rescale=1./255)\nval_data='../input/mnist-standard-data/MNIST Standard set/valid'\nvalidation_generator = valid_datagen.flow_from_directory(val_data,target_size=(48, 48),batch_size=32, class_mode='binary',color_mode=\"grayscale\")\nnm.compile(loss=sparse_categorical_crossentropy,optimizer='rmsprop',metrics=['accuracy'])\nnm.fit(train_generator,steps_per_epoch=16,epochs=20,validation_data=validation_generator,validation_steps=6)","metadata":{"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Found 42000 images belonging to 10 classes.\nFound 600 images belonging to 10 classes.\nEpoch 1/20\n16/16 [==============================] - 3s 130ms/step - loss: 0.9139 - accuracy: 0.7636 - val_loss: 0.5246 - val_accuracy: 0.8333\nEpoch 2/20\n16/16 [==============================] - 2s 101ms/step - loss: 0.5089 - accuracy: 0.8771 - val_loss: 0.3961 - val_accuracy: 0.8594\nEpoch 3/20\n16/16 [==============================] - 2s 100ms/step - loss: 0.3549 - accuracy: 0.8864 - val_loss: 0.4474 - val_accuracy: 0.8333\nEpoch 4/20\n16/16 [==============================] - 2s 98ms/step - loss: 0.3491 - accuracy: 0.8862 - val_loss: 0.2977 - val_accuracy: 0.8906\nEpoch 5/20\n16/16 [==============================] - 2s 96ms/step - loss: 0.3418 - accuracy: 0.8850 - val_loss: 0.2739 - val_accuracy: 0.9167\nEpoch 6/20\n16/16 [==============================] - 2s 98ms/step - loss: 0.2524 - accuracy: 0.9171 - val_loss: 0.1719 - val_accuracy: 0.9531\nEpoch 7/20\n16/16 [==============================] - 2s 95ms/step - loss: 0.3220 - accuracy: 0.8911 - val_loss: 0.2567 - val_accuracy: 0.9271\nEpoch 8/20\n16/16 [==============================] - 2s 102ms/step - loss: 0.3442 - accuracy: 0.8897 - val_loss: 0.1527 - val_accuracy: 0.9531\nEpoch 9/20\n16/16 [==============================] - 1s 93ms/step - loss: 0.2815 - accuracy: 0.8996 - val_loss: 0.3616 - val_accuracy: 0.8802\nEpoch 10/20\n16/16 [==============================] - 1s 92ms/step - loss: 0.2909 - accuracy: 0.9148 - val_loss: 0.2389 - val_accuracy: 0.9167\nEpoch 11/20\n16/16 [==============================] - 1s 93ms/step - loss: 0.3368 - accuracy: 0.9002 - val_loss: 0.1011 - val_accuracy: 0.9531\nEpoch 12/20\n16/16 [==============================] - 1s 88ms/step - loss: 0.2551 - accuracy: 0.9305 - val_loss: 0.1899 - val_accuracy: 0.9427\nEpoch 13/20\n16/16 [==============================] - 2s 96ms/step - loss: 0.2819 - accuracy: 0.9197 - val_loss: 0.1403 - val_accuracy: 0.9479\nEpoch 14/20\n16/16 [==============================] - 1s 87ms/step - loss: 0.1896 - accuracy: 0.9271 - val_loss: 0.1755 - val_accuracy: 0.9427\nEpoch 15/20\n16/16 [==============================] - 1s 88ms/step - loss: 0.2216 - accuracy: 0.9347 - val_loss: 0.1200 - val_accuracy: 0.9479\nEpoch 16/20\n16/16 [==============================] - 1s 88ms/step - loss: 0.1318 - accuracy: 0.9577 - val_loss: 0.0976 - val_accuracy: 0.9740\nEpoch 17/20\n16/16 [==============================] - 1s 90ms/step - loss: 0.1349 - accuracy: 0.9465 - val_loss: 0.1221 - val_accuracy: 0.9479\nEpoch 18/20\n16/16 [==============================] - 1s 87ms/step - loss: 0.1451 - accuracy: 0.9486 - val_loss: 0.1151 - val_accuracy: 0.9583\nEpoch 19/20\n16/16 [==============================] - 1s 88ms/step - loss: 0.1341 - accuracy: 0.9620 - val_loss: 0.1897 - val_accuracy: 0.9375\nEpoch 20/20\n16/16 [==============================] - 1s 88ms/step - loss: 0.3353 - accuracy: 0.9140 - val_loss: 0.0912 - val_accuracy: 0.9688\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f7c3e216bd0>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}